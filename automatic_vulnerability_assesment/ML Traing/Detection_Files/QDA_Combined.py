############## Required Libraries #################
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import accuracy_score
from sklearn import tree
from sklearn import svm
from sklearn.svm import SVC 
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA
from sklearn.metrics import confusion_matrix
from sklearn import linear_model
from sklearn.model_selection import cross_val_score
from numpy.linalg import inv
from math import log1p
from operator import itemgetter
from math import log1p
from math import log
import matplotlib.pyplot as plt
from operator import itemgetter
import matplotlib.patches as mpatches
import csv

##################  Reading data ################
data1 = pd.read_csv('Train_Combined.csv') 
data=data1.values
Data = np.array(data1.drop(['Label'], 1))


data_val = pd.read_csv('Test.csv')
X_val = np.array(data_val.drop(['Label'], 1))
Y_val = data_val.Label



################### splitting into training,validation and test sets ################
number_of_samples= len (data1.Label)
random_indices =np.random.permutation(number_of_samples)
                         #Training set
num_training_samples=int(number_of_samples*1)
X_train=Data[random_indices[:num_training_samples]]
Y_train=data1.Label[random_indices[:num_training_samples]]
'''
                           #Validation set
num_validation_samples=int(number_of_samples*0.3)
X_val=Data[random_indices[num_training_samples :num_training_samples+num_validation_samples]]
Y_val=data1.Label[random_indices[num_training_samples :num_training_samples+num_validation_samples]]
'''
################## Model Selection ################

clf = QDA(store_covariance=True)
model = clf.fit(X_train, Y_train)
scores = cross_val_score(clf, X_train, Y_train, cv=5)
print "Prediction Accuracy on Test Data"
print scores                                              

################## Taking Inputfrom user ################
Y_pred = clf.predict(X_val)
print accuracy_score(Y_val,Y_pred)*100

print "Confusion Matrix"
  
confusion_matrixA = confusion_matrix(Y_val,Y_pred)
total_false = confusion_matrixA[1][0] + confusion_matrixA[0][1]
false_positive = float(confusion_matrixA[0][1])*(float(100)/total_false)
false_negative = 100-false_positive
print "false_positives:",confusion_matrixA[0][1]
print "false_negatives:",confusion_matrixA[1][0]
print "false_positive %age:",false_positive
print "false_negative %age:",false_negative

print "Implementation Parameters:"

c= model.covariances_
c0=inv(np.asmatrix(c[0]))
c1=inv(np.asmatrix(c[1]))
u= model.means_
u0= np.asmatrix(u[0])
u1= np.asmatrix(u[1])
p=model.priors_
p0=log1p(p[0]-1)
p1=log1p(p[1]-1)

v0=-0.5*log(np.linalg.det(c[0]))
v1=-0.5*log(np.linalg.det(c[1]))
w0=-0.5*u0*c0*np.transpose(u0)
w1=-0.5*u1*c1*np.transpose(u1)


xy0 = c0*np.transpose(u0)
xy1 = c1*np.transpose(u1)

print "c0:"
print c0
print "c1:"
print c1
print "u0:"
print xy0
print "u1:"
print xy1
print "w0+v0+p0"
sum0=w0+p0+v0
print sum0
print "w1+v1+p1" 
sum1=w1+p1+v1
print sum1

'''
a = np.empty(len(Data.Label));
for i in range (0,len(Data.Label)):
    x=np.asmatrix(Data1[i,:])
    xt=np.transpose(x)
    y1=(-0.5*x*c1*xt)+(x*c1*np.transpose(u1))+(w1+v1+p1)
    y0=(-0.5*x*c0*xt)+(x*c0*np.transpose(u0))+w0+v0+p0
    if (y1 > y0):
        a[i]='1'
    else: 
        a[i]='0'

'''


'''
a1=raw_input('L1 DCM:')
a2=raw_input('L1 ICM:')
a3=raw_input('L1 TCM:')
a4=raw_input('L2 ICA:')
a5=raw_input('L2 ICM:')
a6=raw_input('L2 TCA:')
a7=raw_input('L2 TCM:')
a8=raw_input('L3 ICA:')
a9=raw_input('L3 TCA:')
a10=raw_input('L3 TCM:')
a11=raw_input('BR MSP:')
a12=raw_input('TOT CYC:')

y = [a1,a2,a3,a4,a5,a6,a7,a8,a9,a10,a11,a12]
#y= [248,58401,49286,164378,43193,101597,45441,41749,44260,43490,214619,58313916]
Y= np.array([y], np.int64)
Result = clf.predict(Y);
if (Result==[0]):
 print 'Normal'
else:
 print 'under Attack'
'''
